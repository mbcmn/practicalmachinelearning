---
title: "Practical Machine Learning Assignment"
author: "Martin Baierl"
date: "10/05/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Practical Machine Learning -Prediction Assignment Writeup
R Markdown  

# Executive Summary
A random forest machine learning algorithm is trained on data from accelerometers to predict whether participants performed barbell lifts correctly or incorrectly and in which way. The algorithm is then used to predict 20 test cases for which the results have been submitted in the Course Project Prediction Quiz.  

# Dataset
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.  

Further details on the dataset used, the Weight Lifting Exercises Dataset, can be found on the following website:
<http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har>  

The training data for this project are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>  
The test data are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>  

# License
The dataset is provided under Creative Commons license (CC BY-SA) by Velloso et al. The following conference paper summarises their work and findings:  

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
<http://web.archive.org/web/20170519033209/http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf>  

# Required Libraries

The below libraries are required. Model training and prediction is undertaken using the  ```{r}caret``` package.  

```{r}
require(caret)
require(parallel)
require(doParallel)
require(corrplot)
require(e1071)
require(ranger)
```



# Getting and Loading the Data
```{r}

pml_train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

pml_train <- read.csv(url(pml_train_url))
pml_test <- read.csv(url(pml_test_url))

dim(pml_train)
dim(pml_test)
```

The training dataset contains 19622 observations for 160 variables, whereas for 20 observations in the test set, the "classe" variable, representing the way the barbell lifting is performed, is to be predicted.

# Data Cleaning

A number of variables appear to refer to the participant, time and window and can therefore be discarded from the set of predictive variables.

```{r}
pml_train <- pml_train[, !(grepl("^X|timestamp|window|user", names(pml_train)))]
pml_test  <- pml_test[, !(grepl("^X|timestamp|window|user", names(pml_test)))]
```

In addition, several variables contain mostly NA values bringing little predictive value and can also be removed, in addition leaving variables only containing NA in the test data causes problems when predicting classe.

```{r}
col.na.train <- colSums(sapply(pml_train, is.na))
col.na.test <- colSums(sapply(pml_test, is.na))

pml_train <- pml_train[,col.na.train == 0 & col.na.test == 0]
pml_test <- pml_test[,col.na.train == 0 & col.na.test == 0]
```

Finally, factor variables in the dataset are converted into numeric variables (with the exception of the Classe variable) and the variable ```{r}problem_id``` is removed from the test set. 

```{r}
classe <- pml_train$classe
colnames_train <- colnames(pml_train)
pml_train[colnames_train]  <- sapply(pml_train, as.numeric)
pml_train$classe <- classe
colnames_test <- colnames(pml_test)
pml_test[colnames_test]   <- sapply(pml_test, as.numeric)
pml_test$problem_id <- NULL
dim(pml_train)
dim(pml_test)
```

# Exploratory Data Analysis

A first step in exploring the data is to identify potential correlations between variables, which is done using ```{r} corrplot```. Positive correlations are displayed in blue and negative correlations in red color. Color intensity and the size of the circle are proportional to the correlation coefficients.

```{r}
cor_mat <- cor(pml_train[-53])
corrplot(cor_mat, method = "circle", type = "lower", tl.cex = 0.7, tl.col = rgb(0,0,0))
```

# Modelling
Prior to any modelling, the dataset needs to be split into a training (75%) and testing (25%) set using the ```{r}createDataPartition()``` function from the caret package. The training set is used to 'train' the model and the testing set will be used for validation and to asses the out of sample performance.

```{r}
inTrain   <- createDataPartition(pml_train$classe, p=0.75, list=F)
trainData <- pml_train[inTrain, ]
testData  <- pml_train[-inTrain, ]
```

The classe will be predicted based on all other variables (```{r} classe ~ .```) using the ```{r}train()``` function in caret using a random forest algorithm ```{r}(method = "rpart)``` and cross-validation. A random seed is set for reproducibility. To speed up processing, parallel processing needs to be activated.


```{r}
set.seed(1234)

cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

fitRf <- train(classe ~ ., data=trainData, method="rf", trControl=trainControl(method="cv", 7, allowParallel = TRUE), ntree=250)
fitRf

stopCluster(cluster)
registerDoSEQ()
```

The trained random forest algorithm is then used with ```{r}predict()``` to predict the classe of the observations in the test set. ```{r}confusionMatrix()``` summarises the results and assess the model accuracy:

```{r}
predictRf <- predict.train(fitRf, testData)
confusionMatrix(testData$classe, predictRf)

```


The random forest algorithm achieves an accuracy of 0.9947 and a Kappa value of 0.9933 on the validation data. The threshold required to predict 20 out of 20 cases correctly with a confidence of 95% is (1-.05)^(1/20) = 99.74%, which is not fully but almost achieved.

The predicted classes for the 20 observations in the test set are shown below:
```{r}
result <- predict.train(fitRf, pml_test)
result
```
